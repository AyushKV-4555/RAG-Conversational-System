{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a6d197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DATA SCIENCE PROJECTS\\LANGGRAPH - CHATBOT\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AnyMessage, AIMessage\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import interrupt, Command\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f449f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"**************************\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61a61436",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd285c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def chat_node(state: ChatState):\n",
    "\n",
    "    decision = interrupt({\n",
    "        \"type\": \"approval\",\n",
    "        \"reason\": \"Model is about to answer a user question.\",\n",
    "        \"question\": state[\"messages\"][-1].content,\n",
    "        \"instruction\": \"Approve this question? yes/no\"\n",
    "    })\n",
    "    \n",
    "    if decision[\"approved\"] == 'no':\n",
    "        return {\"messages\": [AIMessage(content=\"Not approved.\")]}\n",
    "\n",
    "    else:\n",
    "        response = llm.invoke(state[\"messages\"])\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# 3. Build the graph: START -> chat -> END\n",
    "builder = StateGraph(ChatState)\n",
    "\n",
    "builder.add_node(\"chat\", chat_node)\n",
    "\n",
    "builder.add_edge(START, \"chat\")\n",
    "builder.add_edge(\"chat\", END)\n",
    "\n",
    "# Checkpointer is required for interrupts\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Compile the app\n",
    "app = builder.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051d5415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000026B08A65D50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5a7c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new thread id for this conversation\n",
    "config = {\"configurable\": {\"thread_id\": '1234'}}\n",
    "\n",
    "# ---- STEP 1: user asks a question ----\n",
    "initial_input = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"Explain gradient descent in very simple terms.\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Invoke the graph for the first time\n",
    "result = app.invoke(initial_input, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cddd7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Explain gradient descent in very simple terms.', additional_kwargs={}, response_metadata={}, id='195eba2a-366c-4605-907c-80114a9fdbc9')],\n",
       " '__interrupt__': [Interrupt(value={'type': 'approval', 'reason': 'Model is about to answer a user question.', 'question': 'Explain gradient descent in very simple terms.', 'instruction': 'Approve this question? yes/no'}, id='0dd07fed645516e7ae71c98482e534b9')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "633f015c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'approval',\n",
       " 'reason': 'Model is about to answer a user question.',\n",
       " 'question': 'Explain gradient descent in very simple terms.',\n",
       " 'instruction': 'Approve this question? yes/no'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "message = result['__interrupt__'][0].value\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c78aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(f\"\\nBackend message - {message} \\n Approve this question? (y/n): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7827dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Resume the graph with the approval decision\n",
    "final_result = app.invoke(\n",
    "    Command(resume={\"approved\": user_input}),\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "268f9233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Explain gradient descent in very simple terms.', additional_kwargs={}, response_metadata={}, id='195eba2a-366c-4605-907c-80114a9fdbc9'),\n",
       "  AIMessage(content='**Gradient Descent in Simple Terms**\\n\\nImagine you\\'re trying to find the lowest point in a big valley. You can\\'t see the bottom, but you know it\\'s there. You start at the top of the valley and take small steps downhill, adjusting your direction slightly each time based on how steep the slope is.\\n\\n**How Gradient Descent Works:**\\n\\n1. **Start at a random point**: You begin at a random point in the valley (or a mathematical function).\\n2. **Measure the slope**: You measure how steep the slope is at your current point. This is like looking at the angle of the hill.\\n3. **Take a small step**: You take a small step downhill, based on the slope you measured. If the slope is very steep, you take a bigger step.\\n4. **Repeat steps 2-3**: You keep measuring the slope and taking small steps downhill until you reach the bottom of the valley (or the minimum point of the function).\\n\\n**Key Idea:** Gradient Descent is an algorithm that uses this process to find the minimum point of a mathematical function. It\\'s a way to optimize a function by iteratively adjusting the parameters (or \"steps\") until it reaches the optimal solution.\\n\\n**Example:** Suppose you\\'re trying to find the best price to sell a product. You can use gradient descent to adjust the price based on how well it sells, until you find the price that maximizes sales (or minimizes losses).\\n\\nThat\\'s gradient descent in a nutshell!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 305, 'prompt_tokens': 44, 'total_tokens': 349, 'completion_time': 0.481171281, 'completion_tokens_details': None, 'prompt_time': 0.002803558, 'prompt_tokens_details': None, 'queue_time': 0.050095452, 'total_time': 0.483974839}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c0d58-7e7a-78f0-9745-9f022b5bc51d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 44, 'output_tokens': 305, 'total_tokens': 349})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c066170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.types import interrupt, Command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "487b1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "@tool\n",
    "def get_stock_price(symbol: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetch latest stock price for a given symbol (e.g. 'AAPL', 'TSLA') \n",
    "    using Alpha Vantage with API key in the URL.\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        \"https://www.alphavantage.co/query\"\n",
    "        f\"?function=GLOBAL_QUOTE&symbol={symbol}&apikey=C9PE94QUEW9VWGFM\"\n",
    "    )\n",
    "    r = requests.get(url)\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "@tool\n",
    "def purchase_stock(symbol: str, quantity: int) -> dict:\n",
    "    \"\"\"\n",
    "    Simulate purchasing a given quantity of a stock symbol.\n",
    "\n",
    "    HUMAN-IN-THE-LOOP:\n",
    "    Before confirming the purchase, this tool will interrupt\n",
    "    and wait for a human decision (\"yes\" / anything else).\n",
    "    \"\"\"\n",
    "    # This pauses the graph and returns control to the caller\n",
    "    decision = interrupt(f\"Approve buying {quantity} shares of {symbol}? (yes/no)\")\n",
    "\n",
    "    if isinstance(decision, str) and decision.lower() == \"yes\":\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"message\": f\"Purchase order placed for {quantity} shares of {symbol}.\",\n",
    "            \"symbol\": symbol,\n",
    "            \"quantity\": quantity,\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        return {\n",
    "            \"status\": \"cancelled\",\n",
    "            \"message\": f\"Purchase of {quantity} shares of {symbol} was declined by human.\",\n",
    "            \"symbol\": symbol,\n",
    "            \"quantity\": quantity,\n",
    "        }\n",
    "    \n",
    "SYSTEM_PROMPT = SystemMessage(\n",
    "    content=\"\"\"\n",
    "You are an AI assistant with access to tools.\n",
    "\n",
    "STRICT RULES:\n",
    "1. DO NOT call any tool unless the user explicitly asks for:\n",
    "   - real-time data (prices, APIs, status)\n",
    "   - an action (buy, submit, approve, fetch, calculate)\n",
    "2. For normal questions, explanations, or chit-chat:\n",
    "   - respond directly in plain text\n",
    "   - DO NOT use tools\n",
    "3. Use tools ONLY when absolutely required.\n",
    "4. If unsure, ASK a clarification question instead of calling a tool.\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b0ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000022FCCA31710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tools = [get_stock_price, purchase_stock]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "TOOL_KEYWORDS = {\n",
    "    \"price\", \"buy\", \"purchase\", \"stock\",\n",
    "    \"fetch\", \"get\", \"check\", \"approve\", \"calculate\"\n",
    "}\n",
    "\n",
    "def tool_needed(messages):\n",
    "    last = messages[-1].content.lower()\n",
    "    return any(k in last for k in TOOL_KEYWORDS)\n",
    "\n",
    "# -------------------\n",
    "# 3. State\n",
    "# -------------------\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "# -------------------\n",
    "# 4. Nodes\n",
    "# -------------------\n",
    "def chat_node(state: ChatState):\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# -------------------\n",
    "# 5. Checkpointer (in-memory)\n",
    "# -------------------\n",
    "memory = MemorySaver()\n",
    "\n",
    "# -------------------\n",
    "# 6. Graph\n",
    "# -------------------\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"chat_node\", chat_node)\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph.add_edge(START, \"chat_node\")\n",
    "\n",
    "graph.add_conditional_edges(\"chat_node\", tools_condition)\n",
    "graph.add_edge(\"tools\", \"chat_node\")\n",
    "\n",
    "chatbot = graph.compile(checkpointer=memory)\n",
    "\n",
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fb32cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'langchain_core.prompts.chat.ChatPromptTemplate'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m state = {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=user_input)]}\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Run the graph (may hit an interrupt)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m result = \u001b[43mchatbot\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthread_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Check for HITL interrupt from purchase_stock\u001b[39;00m\n\u001b[32m     24\u001b[39m interrupts = result.get(\u001b[33m\"\u001b[39m\u001b[33m__interrupt__\u001b[39m\u001b[33m\"\u001b[39m, [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DATA SCIENCE PROJECTS\\LANGGRAPH - CHATBOT\\myenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DATA SCIENCE PROJECTS\\LANGGRAPH - CHATBOT\\myenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DATA SCIENCE PROJECTS\\LANGGRAPH - CHATBOT\\myenv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DATA SCIENCE PROJECTS\\LANGGRAPH - CHATBOT\\myenv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DATA SCIENCE PROJECTS\\LANGGRAPH - CHATBOT\\myenv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DATA SCIENCE PROJECTS\\LANGGRAPH - CHATBOT\\myenv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mchat_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     14\u001b[39m SYSTEM_PROMPT = SystemMessage(\n\u001b[32m     15\u001b[39m content=\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m    You are an AI assistant with access to tools.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     29\u001b[39m     )\n\u001b[32m     30\u001b[39m messages = SYSTEM_PROMPT + state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m response = \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DATA SCIENCE PROJECTS\\LANGGRAPH - CHATBOT\\myenv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5557\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5550\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5552\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5555\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5556\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5558\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5559\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5560\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5561\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DATA SCIENCE PROJECTS\\LANGGRAPH - CHATBOT\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:403\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    402\u001b[39m             \u001b[38;5;28mself\u001b[39m.generate_prompt(\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m                 [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[32m    404\u001b[39m                 stop=stop,\n\u001b[32m    405\u001b[39m                 callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    406\u001b[39m                 tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    407\u001b[39m                 metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    408\u001b[39m                 run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    409\u001b[39m                 run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    410\u001b[39m                 **kwargs,\n\u001b[32m    411\u001b[39m             ).generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DATA SCIENCE PROJECTS\\LANGGRAPH - CHATBOT\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:386\u001b[39m, in \u001b[36mBaseChatModel._convert_input\u001b[39m\u001b[34m(self, model_input)\u001b[39m\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages=convert_to_messages(model_input))\n\u001b[32m    382\u001b[39m msg = (\n\u001b[32m    383\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    384\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    385\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: Invalid input type <class 'langchain_core.prompts.chat.ChatPromptTemplate'>. Must be a PromptValue, str, or list of BaseMessages.",
      "During task with name 'chat_node' and id 'bf5eeab9-98ce-7f23-d501-d5528a5ca28f'"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# 7. Simple usage example (CLI with HITL)\n",
    "# -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Use a fixed thread_id so the conversation is persisted in memory\n",
    "    thread_id = \"demo-thread\"\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower().strip() in {\"exit\", \"quit\"}:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "    # Build initial state for this turn\n",
    "    state = {\"messages\": [HumanMessage(content=user_input)]}\n",
    "\n",
    "    # Run the graph (may hit an interrupt)\n",
    "    result = chatbot.invoke(\n",
    "        state,\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}},\n",
    "    )\n",
    "\n",
    "    # Check for HITL interrupt from purchase_stock\n",
    "    interrupts = result.get(\"__interrupt__\", [])\n",
    "\n",
    "    if interrupts:\n",
    "        # Our interrupt payload is the string we passed to interrupt(...)\n",
    "        prompt_to_human = interrupts[0].value\n",
    "        print(f\"HITL: {prompt_to_human}\")\n",
    "        decision = input(\"Your decision: \").strip().lower()\n",
    "\n",
    "        # Resume graph with the human decision (\"yes\" / \"no\" / whatever)\n",
    "        result = chatbot.invoke(\n",
    "            Command(resume=decision),\n",
    "            config={\"configurable\": {\"thread_id\": thread_id}},\n",
    "        )\n",
    "\n",
    "    # Get the latest message from the assistant\n",
    "    messages = result[\"messages\"]\n",
    "    last_msg = messages[-1]\n",
    "    print(f\"Bot: {last_msg.content}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4fa04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
